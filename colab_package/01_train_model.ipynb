{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "06f06ee6",
   "metadata": {},
   "source": [
    "# Industrial Safety Equipment Detection - Training Notebook\n",
    "\n",
    "This notebook trains a YOLOv8 model on the synthetic dataset from Duality AI's Falcon platform to detect FireExtinguisher, ToolBox, and OxygenTank objects.\n",
    "\n",
    "## Features:\n",
    "- YOLOv8 architecture with optimized parameters\n",
    "- Enhanced augmentation pipeline\n",
    "- Comprehensive training monitoring\n",
    "- Industrial safety equipment detection (3 classes)\n",
    "- Synthetic dataset from Duality AI's Falcon platform"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a728a467",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff1ff707",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages in Colab\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# Check if running in Colab\n",
    "IN_COLAB = 'google.colab' in sys.modules\n",
    "\n",
    "if IN_COLAB:\n",
    "    !pip install ultralytics\n",
    "    !pip install roboflow\n",
    "    print(\"Packages installed successfully!\")\n",
    "else:\n",
    "    print(\"Not running in Colab - assuming packages are already installed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "058b5493",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import logging\n",
    "from pathlib import Path\n",
    "from typing import Dict, Optional\n",
    "\n",
    "import torch\n",
    "import yaml\n",
    "from ultralytics import YOLO\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "from IPython.display import display, Image as IPImage\n",
    "import pandas as pd\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA device: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"CUDA memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02a015d1",
   "metadata": {},
   "source": [
    "## 2. Configuration and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a0bd132",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training configuration\n",
    "CONFIG = {\n",
    "    'model': {\n",
    "        'architecture': 'yolov8n',\n",
    "        'pretrained': True\n",
    "    },\n",
    "    'training': {\n",
    "        'epochs': 80,\n",
    "        'batch_size': 16,\n",
    "        'learning_rate': 0.001,\n",
    "        'patience': 50,\n",
    "        'optimizer': 'AdamW',\n",
    "        'momentum': 0.937,\n",
    "        'weight_decay': 0.0005,\n",
    "        'warmup_epochs': 3,\n",
    "        'augmentation': {\n",
    "            'hsv_h': 0.015,\n",
    "            'hsv_s': 0.7,\n",
    "            'hsv_v': 0.4,\n",
    "            'degrees': 10.0,\n",
    "            'translate': 0.2,\n",
    "            'scale': 0.5,\n",
    "            'shear': 2.0,\n",
    "            'perspective': 0.0002,\n",
    "            'flipud': 0.5,\n",
    "            'fliplr': 0.5,\n",
    "            'mosaic': 1.0,\n",
    "            'mixup': 0.15,\n",
    "            'copy_paste': 0.3\n",
    "        }\n",
    "    },\n",
    "    'validation': {\n",
    "        'conf_threshold': 0.25,\n",
    "        'iou_threshold': 0.5,\n",
    "        'max_det': 1000\n",
    "    }\n",
    "}\n",
    "\n",
    "# Dataset configuration\n",
    "DATASET_CONFIG = {\n",
    "    'classes': ['FireExtinguisher', 'ToolBox', 'OxygenTank'],\n",
    "    'nc': 3,\n",
    "    'train': 'data/train/images',\n",
    "    'val': 'data/val/images',\n",
    "    'test': 'data/test/images'\n",
    "}\n",
    "\n",
    "print(\"Configuration loaded successfully!\")\n",
    "print(f\"Classes: {DATASET_CONFIG['classes']}\")\n",
    "print(f\"Training epochs: {CONFIG['training']['epochs']}\")\n",
    "print(f\"Batch size: {CONFIG['training']['batch_size']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48af5d05",
   "metadata": {},
   "source": [
    "## 3. Dataset Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6bfe4cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "    handlers=[\n",
    "        logging.StreamHandler(sys.stdout)\n",
    "    ]\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "def get_device():\n",
    "    \"\"\"Get the best available device.\"\"\"\n",
    "    if torch.cuda.is_available():\n",
    "        device = torch.device('cuda')\n",
    "        logger.info(f\"Using GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    else:\n",
    "        device = torch.device('cpu')\n",
    "        logger.info(\"Using CPU\")\n",
    "    return device\n",
    "\n",
    "device = get_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1376f0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataset YAML file\n",
    "def create_dataset_yaml(config_dict, save_path='dataset.yaml'):\n",
    "    \"\"\"Create dataset YAML configuration file.\"\"\"\n",
    "    with open(save_path, 'w') as f:\n",
    "        yaml.dump(config_dict, f, default_flow_style=False)\n",
    "    logger.info(f\"Dataset YAML created: {save_path}\")\n",
    "    return save_path\n",
    "\n",
    "# Create the dataset YAML\n",
    "dataset_yaml_path = create_dataset_yaml(DATASET_CONFIG)\n",
    "\n",
    "# Display the YAML content\n",
    "with open(dataset_yaml_path, 'r') as f:\n",
    "    print(\"Dataset YAML content:\")\n",
    "    print(f.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46e2f2e5",
   "metadata": {},
   "source": [
    "## 4. Data Analysis and Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec28e15a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_dataset(data_path='data'):\n",
    "    \"\"\"Analyze the dataset structure and statistics.\"\"\"\n",
    "    data_path = Path(data_path)\n",
    "    \n",
    "    splits = ['train', 'val', 'test']\n",
    "    stats = {}\n",
    "    \n",
    "    for split in splits:\n",
    "        images_path = data_path / split / 'images'\n",
    "        labels_path = data_path / split / 'labels'\n",
    "        \n",
    "        if images_path.exists():\n",
    "            image_files = list(images_path.glob('*.png')) + list(images_path.glob('*.jpg'))\n",
    "            stats[split] = {\n",
    "                'images': len(image_files),\n",
    "                'labels': len(list(labels_path.glob('*.txt'))) if labels_path.exists() else 0\n",
    "            }\n",
    "        else:\n",
    "            stats[split] = {'images': 0, 'labels': 0}\n",
    "    \n",
    "    # Display statistics\n",
    "    print(\"Dataset Statistics:\")\n",
    "    print(\"=\"*50)\n",
    "    for split, data in stats.items():\n",
    "        print(f\"{split.capitalize()}: {data['images']} images, {data['labels']} labels\")\n",
    "    \n",
    "    total_images = sum(data['images'] for data in stats.values())\n",
    "    total_labels = sum(data['labels'] for data in stats.values())\n",
    "    print(f\"Total: {total_images} images, {total_labels} labels\")\n",
    "    \n",
    "    return stats\n",
    "\n",
    "# Analyze dataset if it exists\n",
    "if os.path.exists('data'):\n",
    "    dataset_stats = analyze_dataset()\n",
    "else:\n",
    "    print(\"Dataset not found. Please upload your dataset to the 'data' directory.\")\n",
    "    print(\"Expected structure:\")\n",
    "    print(\"data/\")\n",
    "    print(\"├── train/\")\n",
    "    print(\"│   ├── images/\")\n",
    "    print(\"│   └── labels/\")\n",
    "    print(\"├── val/\")\n",
    "    print(\"│   ├── images/\")\n",
    "    print(\"│   └── labels/\")\n",
    "    print(\"└── test/\")\n",
    "    print(\"    ├── images/\")\n",
    "    print(\"    └── labels/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93aa00dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_class_distribution(labels_dir, class_names):\n",
    "    \"\"\"Plot class distribution from label files.\"\"\"\n",
    "    labels_dir = Path(labels_dir)\n",
    "    class_counts = {i: 0 for i in range(len(class_names))}\n",
    "    \n",
    "    for label_file in labels_dir.glob('*.txt'):\n",
    "        try:\n",
    "            with open(label_file, 'r') as f:\n",
    "                for line in f:\n",
    "                    if line.strip():\n",
    "                        class_id = int(line.split()[0])\n",
    "                        if class_id in class_counts:\n",
    "                            class_counts[class_id] += 1\n",
    "        except Exception as e:\n",
    "            continue\n",
    "    \n",
    "    # Plot distribution\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    classes = [class_names[i] for i in range(len(class_names))]\n",
    "    counts = [class_counts[i] for i in range(len(class_names))]\n",
    "    \n",
    "    plt.bar(classes, counts, color=['#FF6B6B', '#4ECDC4', '#45B7D1'])\n",
    "    plt.title('Class Distribution in Training Set', fontsize=16, fontweight='bold')\n",
    "    plt.xlabel('Classes', fontsize=12)\n",
    "    plt.ylabel('Number of Instances', fontsize=12)\n",
    "    plt.xticks(rotation=45)\n",
    "    \n",
    "    # Add value labels on bars\n",
    "    for i, v in enumerate(counts):\n",
    "        plt.text(i, v + max(counts) * 0.01, str(v), ha='center', va='bottom', \n",
    "                 fontweight='bold', fontsize=11)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.grid(axis='y', alpha=0.3)\n",
    "    plt.show()\n",
    "    \n",
    "    return class_counts\n",
    "\n",
    "# Plot class distribution if training labels exist\n",
    "if os.path.exists('data/train/labels'):\n",
    "    class_distribution = plot_class_distribution('data/train/labels', DATASET_CONFIG['classes'])\n",
    "    print(f\"Class distribution: {class_distribution}\")\n",
    "else:\n",
    "    print(\"Training labels not found. Skipping class distribution plot.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0c27736",
   "metadata": {},
   "source": [
    "## 5. Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d521136c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_training_parameters(config):\n",
    "    \"\"\"Setup training parameters from configuration.\"\"\"\n",
    "    \n",
    "    device_str = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    \n",
    "    train_params = {\n",
    "        'data': 'dataset.yaml',\n",
    "        'epochs': config['training']['epochs'],\n",
    "        'batch': config['training']['batch_size'],\n",
    "        'lr0': config['training']['learning_rate'],\n",
    "        'imgsz': 640,\n",
    "        'device': device_str,\n",
    "        'workers': 8 if device_str == 'cuda' else 4,\n",
    "        'project': 'runs/train',\n",
    "        'name': 'industrial_safety_detection',\n",
    "        'save_period': 10,\n",
    "        'patience': config['training']['patience'],\n",
    "        'optimizer': config['training']['optimizer'],\n",
    "        'momentum': config['training']['momentum'],\n",
    "        'weight_decay': config['training']['weight_decay'],\n",
    "        'warmup_epochs': config['training']['warmup_epochs'],\n",
    "        'verbose': True,\n",
    "        'seed': 42,\n",
    "        'deterministic': True,\n",
    "        'single_cls': False,\n",
    "        'rect': False,\n",
    "        'cos_lr': True,\n",
    "        'close_mosaic': 10,\n",
    "        'amp': True,\n",
    "        'fraction': 1.0,\n",
    "        'profile': False,\n",
    "        'freeze': None,\n",
    "        'multi_scale': False,\n",
    "        'overlap_mask': True,\n",
    "        'mask_ratio': 4,\n",
    "        'dropout': 0.0,\n",
    "        'val': True,\n",
    "        'plots': True,\n",
    "        'save': True,\n",
    "        'save_json': False,\n",
    "        'save_hybrid': False,\n",
    "        'conf': config['validation']['conf_threshold'],\n",
    "        'iou': config['validation']['iou_threshold'],\n",
    "        'max_det': config['validation']['max_det'],\n",
    "        'half': False,\n",
    "        'dnn': False,\n",
    "        'exist_ok': True,\n",
    "    }\n",
    "    \n",
    "    # Add augmentation parameters\n",
    "    aug_config = config['training']['augmentation']\n",
    "    train_params.update({\n",
    "        'hsv_h': aug_config['hsv_h'],\n",
    "        'hsv_s': aug_config['hsv_s'],\n",
    "        'hsv_v': aug_config['hsv_v'],\n",
    "        'degrees': aug_config['degrees'],\n",
    "        'translate': aug_config['translate'],\n",
    "        'scale': aug_config['scale'],\n",
    "        'shear': aug_config['shear'],\n",
    "        'perspective': aug_config['perspective'],\n",
    "        'flipud': aug_config['flipud'],\n",
    "        'fliplr': aug_config['fliplr'],\n",
    "        'mosaic': aug_config['mosaic'],\n",
    "        'mixup': aug_config['mixup'],\n",
    "        'copy_paste': aug_config['copy_paste'],\n",
    "    })\n",
    "    \n",
    "    return train_params\n",
    "\n",
    "# Setup training parameters\n",
    "train_params = setup_training_parameters(CONFIG)\n",
    "\n",
    "print(\"Training Parameters:\")\n",
    "print(\"=\"*50)\n",
    "for key, value in train_params.items():\n",
    "    if key in ['hsv_h', 'hsv_s', 'hsv_v', 'degrees', 'translate', 'scale', 'shear', 'perspective']:\n",
    "        continue  # Skip augmentation params for brevity\n",
    "    print(f\"{key}: {value}\")\n",
    "print(\"\\nAugmentation enabled with optimized parameters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8bdaebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and initialize the model\n",
    "model_name = f\"{CONFIG['model']['architecture']}.pt\"\n",
    "logger.info(f\"Loading model: {model_name}\")\n",
    "\n",
    "model = YOLO(model_name)\n",
    "\n",
    "# Model information\n",
    "print(f\"Model: {model_name}\")\n",
    "print(f\"Parameters: {sum(p.numel() for p in model.model.parameters()):,}\")\n",
    "print(f\"Model summary:\")\n",
    "model.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64299a05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start training\n",
    "logger.info(\"Starting training...\")\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"STARTING TRAINING\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "try:\n",
    "    results = model.train(**train_params)\n",
    "    logger.info(\"Training completed successfully!\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"TRAINING COMPLETED SUCCESSFULLY!\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "except Exception as e:\n",
    "    logger.error(f\"Training failed: {e}\")\n",
    "    print(f\"Training failed with error: {e}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5088d1d2",
   "metadata": {},
   "source": [
    "## 6. Training Results Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f2a113c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display training results\n",
    "results_dir = Path('runs/train/industrial_safety_detection')\n",
    "\n",
    "if results_dir.exists():\n",
    "    print(f\"Results saved to: {results_dir}\")\n",
    "    print(\"\\nTraining artifacts:\")\n",
    "    \n",
    "    # List key files\n",
    "    key_files = [\n",
    "        'results.png',\n",
    "        'confusion_matrix.png', \n",
    "        'train_batch0.jpg',\n",
    "        'val_batch0_pred.jpg',\n",
    "        'weights/best.pt',\n",
    "        'weights/last.pt'\n",
    "    ]\n",
    "    \n",
    "    for file in key_files:\n",
    "        file_path = results_dir / file\n",
    "        if file_path.exists():\n",
    "            print(f\"  ✓ {file}\")\n",
    "        else:\n",
    "            print(f\"  ✗ {file} (not found)\")\n",
    "else:\n",
    "    print(\"Results directory not found. Training may not have completed successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4884c4dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display training curves\n",
    "results_img_path = results_dir / 'results.png'\n",
    "if results_img_path.exists():\n",
    "    print(\"Training Results:\")\n",
    "    display(IPImage(str(results_img_path)))\n",
    "else:\n",
    "    print(\"Training results image not found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6755bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display confusion matrix\n",
    "confusion_matrix_path = results_dir / 'confusion_matrix.png'\n",
    "if confusion_matrix_path.exists():\n",
    "    print(\"Confusion Matrix:\")\n",
    "    display(IPImage(str(confusion_matrix_path)))\n",
    "else:\n",
    "    print(\"Confusion matrix not found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c9e9c30",
   "metadata": {},
   "source": [
    "## 7. Model Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fae24c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load best model and run validation\n",
    "best_model_path = results_dir / 'weights' / 'best.pt'\n",
    "if best_model_path.exists():\n",
    "    logger.info(\"Loading best model for validation...\")\n",
    "    best_model = YOLO(str(best_model_path))\n",
    "    \n",
    "    # Run validation\n",
    "    logger.info(\"Running final validation...\")\n",
    "    val_results = best_model.val()\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"FINAL VALIDATION RESULTS\")\n",
    "    print(\"=\"*50)\n",
    "    print(f\"mAP@0.5: {val_results.box.map50:.4f}\")\n",
    "    print(f\"mAP@0.5:0.95: {val_results.box.map:.4f}\")\n",
    "    print(f\"Precision: {val_results.box.mp:.4f}\")\n",
    "    print(f\"Recall: {val_results.box.mr:.4f}\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "else:\n",
    "    print(\"Best model not found. Training may not have completed successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "810a3ec7",
   "metadata": {},
   "source": [
    "## 8. Sample Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37658a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display sample validation predictions\n",
    "val_pred_path = results_dir / 'val_batch0_pred.jpg'\n",
    "if val_pred_path.exists():\n",
    "    print(\"Sample Validation Predictions:\")\n",
    "    display(IPImage(str(val_pred_path)))\n",
    "else:\n",
    "    print(\"Validation predictions image not found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e04065f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test on a sample image if test data exists\n",
    "test_images_dir = Path('data/test/images')\n",
    "if test_images_dir.exists() and best_model_path.exists():\n",
    "    test_images = list(test_images_dir.glob('*.png'))[:3]  # Take first 3 images\n",
    "    \n",
    "    if test_images:\n",
    "        print(\"Sample Test Predictions:\")\n",
    "        \n",
    "        for i, img_path in enumerate(test_images):\n",
    "            print(f\"\\nImage {i+1}: {img_path.name}\")\n",
    "            \n",
    "            # Run prediction\n",
    "            results = best_model.predict(str(img_path), conf=0.25, save=True, project='runs/predict', name=f'test_sample_{i}')\n",
    "            \n",
    "            # Display results\n",
    "            for result in results:\n",
    "                if len(result.boxes) > 0:\n",
    "                    print(f\"  Detected {len(result.boxes)} objects\")\n",
    "                    for box in result.boxes:\n",
    "                        class_id = int(box.cls)\n",
    "                        confidence = float(box.conf)\n",
    "                        class_name = DATASET_CONFIG['classes'][class_id]\n",
    "                        print(f\"    {class_name}: {confidence:.3f}\")\n",
    "                else:\n",
    "                    print(\"  No objects detected\")\n",
    "    else:\n",
    "        print(\"No test images found.\")\n",
    "else:\n",
    "    print(\"Test data or trained model not available for sample predictions.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf791496",
   "metadata": {},
   "source": [
    "## 9. Export Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "084b90e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export model to different formats\n",
    "if best_model_path.exists():\n",
    "    logger.info(\"Exporting model to different formats...\")\n",
    "    \n",
    "    try:\n",
    "        # Export to ONNX\n",
    "        best_model.export(format='onnx', opset=11)\n",
    "        print(\"✓ Model exported to ONNX format\")\n",
    "        \n",
    "        # Export to TensorRT (if available)\n",
    "        if torch.cuda.is_available():\n",
    "            try:\n",
    "                best_model.export(format='engine')\n",
    "                print(\"✓ Model exported to TensorRT format\")\n",
    "            except Exception as e:\n",
    "                print(f\"⚠ TensorRT export failed: {e}\")\n",
    "        \n",
    "        # Export to CoreML (for iOS)\n",
    "        try:\n",
    "            best_model.export(format='coreml')\n",
    "            print(\"✓ Model exported to CoreML format\")\n",
    "        except Exception as e:\n",
    "            print(f\"⚠ CoreML export failed: {e}\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Export failed: {e}\")\n",
    "else:\n",
    "    print(\"Best model not found. Cannot export.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c965e20",
   "metadata": {},
   "source": [
    "## 10. Summary and Next Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87332f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"TRAINING SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Model: {CONFIG['model']['architecture']}\")\n",
    "print(f\"Classes: {', '.join(DATASET_CONFIG['classes'])}\")\n",
    "print(f\"Training epochs: {CONFIG['training']['epochs']}\")\n",
    "print(f\"Batch size: {CONFIG['training']['batch_size']}\")\n",
    "print(f\"Optimizer: {CONFIG['training']['optimizer']}\")\n",
    "print(f\"Device: {'GPU' if torch.cuda.is_available() else 'CPU'}\")\n",
    "\n",
    "if best_model_path.exists():\n",
    "    print(f\"\\nModel saved to: {best_model_path}\")\n",
    "    print(f\"Results directory: {results_dir}\")\n",
    "    \n",
    "print(\"\\nNext Steps:\")\n",
    "print(\"1. Review training curves and validation results\")\n",
    "print(\"2. Test the model on new images using inference notebook\")\n",
    "print(\"3. Fine-tune hyperparameters if needed\")\n",
    "print(\"4. Deploy the model for production use\")\n",
    "print(\"=\"*60)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
